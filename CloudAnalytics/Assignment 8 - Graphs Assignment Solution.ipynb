{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:red;font-size:60px\">GraphFrames Assignment</span>\n",
    "<br><br>\n",
    "In this assignment, you need to do the following:\n",
    "<li>Read the file 201710-citibike-tripdata.csv</li>\n",
    "<li>Construct a graph with stations as vertices and trips between stations as edges</li>\n",
    "<li>Vertex Ids are station numbers and Vertex attributes are station names</li>\n",
    "<li>Edge attributes are trip duration (durations are in seconds)</li>\n",
    "<li>Then answer the questions below</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.packages= [\"graphframes:graphframes:0.8.3-spark3.4-s_2.12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.7.189:4040\n",
       "SparkContext available as 'sc' (version = 3.4.1, master = local[*], app id = local-1699076829907)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql._\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.graphframes._\n",
       "import org.apache.spark.graphx._\n",
       "import org.apache.spark.rdd.RDD\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//GraphFrame imports\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.graphframes._\n",
    "\n",
    "\n",
    "//GraphX imports\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Step 1: Construct the graph</span>\n",
    "<br><br>\n",
    "<li>read the data file and drop the header line</li>\n",
    "<li>create a vertex dataframe (the union of start stations and end stations)</li>\n",
    "<li>create an edge dataframe (the trips - start station id, end station id, duration)</li>\n",
    "<li>create a GraphFrame</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text: org.apache.spark.rdd.RDD[String] = /Users/hardeepjohar/Documents/Courses/Fall2022/AnalyticsOnTheCloud/Assignments/201710-citibike-tripdata.csv MapPartitionsRDD[1] at textFile at <console>:37\n",
       "data: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[3] at map at <console>:39\n",
       "start_station: org.apache.spark.rdd.RDD[(Int, String)] = MapPartitionsRDD[7] at distinct at <console>:41\n",
       "end_station: org.apache.spark.rdd.RDD[(Int, String)] = MapPartitionsRDD[11] at distinct at <console>:42\n",
       "vertices: org.apache.spark.sql.DataFrame = [id: int, location: string]\n",
       "edges: org.apache.spark.sql.DataFrame = [src: int, dst: int ... 1 more field]\n",
       "g: org.graphframes.GraphFrame = GraphFrame(v:[id: int, location: string], e:[src: int, dst: int ... 1 more field])\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val text = sc.textFile(\"/Users/hardeepjohar/Documents/Courses/Fall2022/AnalyticsOnTheCloud/Assignments/201710-citibike-tripdata.csv\")\n",
    "val data = text.mapPartitionsWithIndex{ (idx,iter) => if (idx == 0) iter.drop(1) else iter }\n",
    "    .map(l => l.split(\",\"))\n",
    "//val data = data_noh.map(l => l.split(\",\"))\n",
    "val start_station = data.map(f => (f(3).toInt,f(4))).distinct\n",
    "val end_station = data.map(f => (f(7).toInt,f(8))).distinct\n",
    "val vertices = start_station.union(end_station).distinct.toDF(\"id\",\"location\")\n",
    "val edges = data.map(l => (l(3).toInt,l(7).toInt,l(0).toDouble)).toDF(\"src\",\"dst\",\"duration\")\n",
    "\n",
    "val g = GraphFrame(vertices,edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+\n",
      "| src| dst|duration|\n",
      "+----+----+--------+\n",
      "| 479| 478|   457.0|\n",
      "| 279| 307|  6462.0|\n",
      "| 504| 350|   761.0|\n",
      "|3236|3233|  1193.0|\n",
      "|2006| 469|  2772.0|\n",
      "|3443| 468|   260.0|\n",
      "| 478|3224|   715.0|\n",
      "|3305| 305|   808.0|\n",
      "| 284| 355|  1143.0|\n",
      "| 432| 295|   527.0|\n",
      "|3430|3090|   516.0|\n",
      "|2006| 469|  2764.0|\n",
      "| 470| 458|   439.0|\n",
      "|3414|3346|   292.0|\n",
      "|3328|3314|   242.0|\n",
      "|3414|3346|   284.0|\n",
      "|3430|3109|   573.0|\n",
      "| 161| 537|  1289.0|\n",
      "|2006| 469|  2739.0|\n",
      "| 440| 445|   949.0|\n",
      "+----+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edges.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Step 2: Basic questions</span>\n",
    "<br><br>\n",
    "\n",
    "<li>How many citibike stations are there in the network?</li>\n",
    "<li>How many trips were made in the month in question?</li>\n",
    "<li>How many trips started and ended at the same station?</li>\n",
    "<li>How many station to station connections are there (at least one edge exists between station i and station j and i is not equal to j)?</li>\n",
    "<li>Your code should print:</li>\n",
    "<pre>\n",
    "Total number of stations: 785\n",
    "Total number of trips.  : 1897592\n",
    "Trips that started and ended at the same station: 33245\n",
    "Number of station to station connections: 107524\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_undirected_graph: (g: org.graphframes.GraphFrame)org.graphframes.GraphFrame\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_undirected_graph(g: GraphFrame) = {\n",
    "    val u_edge_df = g.find(\"(a)-[]->(b)\")\n",
    "        .select($\"a.id\".as(\"src\"),$\"b.id\".as(\"dst\"))\n",
    "        .withColumn(\"swap\",when(col(\"src\")<col(\"dst\"),col(\"dst\")))\n",
    "        .withColumn(\"dst\",\n",
    "                    when(col(\"swap\").isNotNull,col(\"src\"))\n",
    "                    .otherwise(col(\"dst\")))\n",
    "        .withColumn(\"src\",\n",
    "                    when(col(\"swap\").isNotNull,col(\"swap\"))\n",
    "                   .otherwise(col(\"src\")))\n",
    "        .drop(col(\"swap\"))\n",
    "        .distinct\n",
    "    val u_vertices_df = g.vertices\n",
    "    val u_g = GraphFrame(u_vertices_df,u_edge_df)    \n",
    "    u_g\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stations: 785\n",
      "Total number of trips.  : 1897592\n",
      "Trips that started and ended at the same station: 33245\n",
      "Number of station to station connections: 107524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "r1: org.apache.spark.sql.DataFrame = [src: int, dst: int ... 1 more field]\n",
       "r2: Long = 107524\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"Total number of stations: \"+g.vertices.count)\n",
    "println(\"Total number of trips.  : \"+g.edges.count)\n",
    "g.edges.createOrReplaceTempView(\"edgeDB\")\n",
    "val r1 = spark.sql(\"select * from edgeDB where src==dst\")\n",
    "println(\"Trips that started and ended at the same station: \"+r1.count)\n",
    "val r2 = make_undirected_graph(GraphFrame(vertices,spark.sql(\"select * from edgeDB where src!=dst\"))).edges.count\n",
    "println(\"Number of station to station connections: \"+r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[98] at mapPartitionsWithIndex at <console>:40\n",
       "start_station_name: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[100] at map at <console>:42\n",
       "end_station_name: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[102] at map at <console>:43\n",
       "start_df: org.apache.spark.sql.DataFrame = [name: string, id: int]\n",
       "end_df: org.apache.spark.sql.DataFrame = [name: string, id: int]\n",
       "all_station: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [name: string, id: int]\n",
       "edge_info: org.apache.spark.rdd.RDD[(Int, Int, Int)] = MapPartitionsRDD[104] at map at <console>:49\n",
       "vertex_df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [name: string, id: int]\n",
       "edge_df: org.apache.spark.sql.DataFrame = [src: int, dst: int ....\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val text = sc.textFile(\"/Users/hardeepjohar/Documents/Courses/Fall2022/AnalyticsOnTheCloud/Assignments/201710-citibike-tripdata.csv\").mapPartitionsWithIndex{(idx,iter) => if (idx==0) iter.drop(1) else iter}\n",
    "\n",
    "val start_station_name = text.map(x=>x.split(\",\")).map(x=>(x(4),x(3).toInt))\n",
    "val end_station_name = text.map(x=>x.split(\",\")).map(x=>(x(8),x(7).toInt))\n",
    "\n",
    "val start_df = start_station_name.toDF(\"name\",\"id\")\n",
    "val end_df = end_station_name.toDF(\"name\",\"id\")\n",
    "val all_station = start_df.union(end_df).distinct()\n",
    "\n",
    "val edge_info = text.map(x=>x.split(\",\")).map(x=>(x(3).toInt,x(7).toInt,x(0).toInt))\n",
    "\n",
    "val vertex_df = all_station\n",
    "val edge_df = edge_info.toDF(\"src\",\"dst\",\"attr\")\n",
    "\n",
    "val g_2 = GraphFrame(vertex_df,edge_df)\n",
    "\n",
    "val undirected_g2 = make_undirected_graph(g_2)\n",
    "val s2s_connection = undirected_g2.find(\"(a)-[]->(b)\").filter(\"a.id!=b.id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Long = 107524\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Step 3: Find the Station from which most trips originate</span>\n",
    "<br><br>\n",
    "<li>Note that the graph has one edge for each trip (i.e., there are many edges between pairs of vertices)</li>\n",
    "<li>The function <span style=\"color:blue\">outDegrees</span> returns the number of outgoing edges from every vertex</li>\n",
    "<li>Print the name of the station with most originating trips</li>\n",
    "<li>Your code should print:</li>\n",
    "<pre>  \n",
    "The station from which most trips originate is: \"Pershing Square North\"\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val out = g.outDegrees\n",
    "out.createOrReplaceTempView(\"outdegreesDB\")\n",
    "val maxout = spark.sql(\"select id from outdegreesDB where outDegree = (select max(outDegree) from outdegreesDB)\")\n",
    "println(\"The station from which most trips originate is: \" + maxout.join(g.vertices,maxout(\"id\") === g.vertices(\"id\")).select(\"location\").rdd.collect()(0)(0).toString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 4: Proportion of trips for each station that start and end at that same station</span>\n",
    "<br><br>\n",
    "<li>Create a GraphX graph from the GraphFrames graph (use the method that retains datatypes)</li>\n",
    "<li>Use aggregateMessages to calculate the number of trips that start and end at the same vertex (for each vertex)</li>\n",
    "<li>Convert the resulting (VertexRDD) to a DataFrame</li>\n",
    "<li>Using join add the location of the station column to the result df from the previous step and then use select to create a dataframe with the schema (vertex, location, trips)</li>\n",
    "<li>Join this df to the out degrees df created earlier</li>\n",
    "<li>Divide the \"same trips\" column by the \"out degrees column\" </li>\n",
    "<li>Sort the resulting df by this proportion in descending order</li>\n",
    "<li>Your output should be the following dataframe\n",
    "<pre>\n",
    "+----+--------------------+-----+---------+-------------------+\n",
    "|  id|            location|trips|outDegree|               prop|\n",
    "+----+--------------------+-----+---------+-------------------+\n",
    "|3488|  \"8D QC Station 01\"|    1|        1|                1.0|\n",
    "|3245|\"NYCBS DEPOT - DE...|    1|        2|                0.5|\n",
    "|3182|\"Yankee Ferry Ter...|  309|      900| 0.3433333333333333|\n",
    "|3254|  \"Soissons Landing\"|  358|     1100|0.32545454545454544|\n",
    "|3342|\"Pioneer St & Ric...|   59|      299|0.19732441471571907|\n",
    "|3477|\"39 St & 2 Ave - ...|   45|      245| 0.1836734693877551|\n",
    "|3532|\"Ditmars Blvd & 1...|   70|      407|  0.171990171990172|\n",
    "|3180|\"Brooklyn Bridge ...|  232|     1354|0.17134416543574593|\n",
    "|3423|\"West Drive & Pro...|  367|     2463|0.14900527811611855|\n",
    "|3636|\"Expansion Wareho...|    1|        8|              0.125|\n",
    "|3302|\"Columbus Ave & W...|   74|      598|0.12374581939799331|\n",
    "|3120|\"Center Blvd & Bo...|   74|      622| 0.1189710610932476|\n",
    "|3514|\"Astoria Park S &...|   34|      299|0.11371237458193979|\n",
    "|3479|      \"Picnic Point\"|   77|      712|0.10814606741573034|\n",
    "|3594|\"Montgomery St & ...|    9|       87|0.10344827586206896|\n",
    "|3524|    \"19 St & 24 Ave\"|   24|      249| 0.0963855421686747|\n",
    "|3349|\"Grand Army Plaza...|  237|     2570|0.09221789883268483|\n",
    "|3333|\"Columbia St & Lo...|    5|       55|0.09090909090909091|\n",
    "|3354|\"3 St & Prospect ...|  142|     1572|0.09033078880407125|\n",
    "|3607|    \"31 Ave & 14 St\"|   10|      113|0.08849557522123894|\n",
    "+----+--------------------+-----+---------+-------------------+\n",
    "only showing top 20 rows\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val v = g.vertices.rdd.map(r => (r(0).toString.toLong,r(1).toString))\n",
    "val e = g.edges.rdd.map(r => Edge(r(0).toString.toLong,r(1).toString.toLong,r(2).toString.toDouble))\n",
    "val gx: Graph[String, Double] = Graph(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val same_trips = gx.aggregateMessages[Int](ec => ec.sendToSrc(if (ec.srcId == ec.dstId) 1 else 0),(x,y) => x+y)\n",
    "                    .toDF(\"vertex\",\"trips\")\n",
    "same_trips.join(g.vertices,g.vertices(\"id\")===same_trips(\"vertex\"))\n",
    "            .select(\"vertex\",\"location\",\"trips\")\n",
    "            .join(out,same_trips(\"vertex\")===out(\"id\")).select(\"id\",\"location\",\"trips\",\"outDegree\")\n",
    "            .withColumn(\"prop\",col(\"trips\")/col(\"outDegree\"))\n",
    "            .orderBy(desc(\"prop\"))\n",
    "            .show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 5: Create a new graph that contains all edges except for those between the same station</span>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val new_g = g.filterEdges(\"src != dst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_g.edges.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 6: Calculate the average duration between every pair of stations</span>\n",
    "<br><br>\n",
    "<li>use the new graph from step 5 for this</li>\n",
    "<li>I'll let you figure this out but this should be really easy (think SQL)</li>\n",
    "<pre>\n",
    "+----+----+------------------+\n",
    "| src| dst|                 m|\n",
    "+----+----+------------------+\n",
    "| 504| 350| 772.7647058823529|\n",
    "| 433| 527| 532.9677419354839|\n",
    "| 434| 470|316.52272727272725|\n",
    "| 438| 151|  546.195652173913|\n",
    "| 445| 507| 553.3947368421053|\n",
    "|2021| 446| 827.6904761904761|\n",
    "| 116| 518| 1115.857142857143|\n",
    "|3435| 358| 895.6666666666666|\n",
    "|3402|3414| 634.1666666666666|\n",
    "| 498| 495| 801.2272727272727|\n",
    "|3637| 418|             889.7|\n",
    "| 380|3260|419.42105263157896|\n",
    "|3360| 507|            1442.0|\n",
    "| 326| 247|             713.0|\n",
    "|3358| 467| 500.6666666666667|\n",
    "|3164| 457|502.97241379310344|\n",
    "| 498| 528| 434.3207547169811|\n",
    "| 405|3256| 843.2168674698795|\n",
    "| 477|2000|2672.3333333333335|\n",
    "|3226|3163| 686.4444444444445|\n",
    "+----+----+------------------+\n",
    "only showing top 20 rows\n",
    "<pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_g.edges.createOrReplaceTempView(\"edgesDB\")\n",
    "val result = spark.sql(\"select src,dst,mean(duration) as m from edgesDB group by src,dst\")\n",
    "result.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 7: Important stations</span><br><br>\n",
    "Citibike wants to figure out how best to deploy its workers in checking whether a station is over-full (too many bikes) or needs more bikes. It figures that the best way to do this is to find out which stations are the most important in terms of flows:\n",
    "<li>A station that has high bike returns and is connected to other stations with high bike returns is more likely to have too many bikes in its station and therefore should be monitored more often</li>\n",
    "<li>A station that has high bike pickups and is connected to other stations with high bike pickups is more likely to be short of bikes and therefore should be monitored more often</li>\n",
    "<li>Calculate the propensities for over-fullness and emptiness for every station</li>\n",
    "<li>Report the 5 most important stations for over-fullness (use pageRank on the graph)</li>\n",
    "<li>Report the 5 most important stations for emptiness (reverse all the edges on the graph and use pageRank)</li>\n",
    "<li>Your results (Don't worry about the meaning of location names!):</li>\n",
    "<pre>\n",
    "+---+--------------------+------------------+\n",
    "| id|            location|          pagerank|\n",
    "+---+--------------------+------------------+\n",
    "|519|\"Pershing Square ...| 4.930887390071603|\n",
    "|426|\"West St & Chambe...|3.7410934274030576|\n",
    "|402|\"Broadway & E 22 St\"|  3.58520147183096|\n",
    "|497|\"E 17 St & Broadway\"| 3.537658018512581|\n",
    "|435|   \"W 21 St & 6 Ave\"| 3.438585855241344|\n",
    "+---+--------------------+------------------+\n",
    "\n",
    "+----+--------------------+------------------+\n",
    "|  id|            location|          pagerank|\n",
    "+----+--------------------+------------------+\n",
    "|3197|      \"Hs Don't Use\"| 5.710640869520747|\n",
    "| 519|\"Pershing Square ...| 5.012823444592195|\n",
    "|3480|      \"WS Don't Use\"| 4.272284643284593|\n",
    "| 402|\"Broadway & E 22 St\"|3.4515211069038183|\n",
    "| 497|\"E 17 St & Broadway\"|3.3347259745457443|\n",
    "+----+--------------------+------------------+\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val ranks = g.pageRank.resetProbability(0.15).tol(0.0001)\n",
    "                .run()\n",
    "                .vertices\n",
    "                .orderBy(desc(\"pagerank\"))\n",
    "                .limit(5)\n",
    "                .show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val e2 = g.edges.withColumn(\"temp\",col(\"src\"))\n",
    "        .withColumn(\"src\",col(\"dst\"))\n",
    "        .withColumn(\"dst\",col(\"temp\"))\n",
    "        .select(\"src\",\"dst\",\"duration\")\n",
    "val g2 = GraphFrame(vertices,e2)\n",
    "val ranks = g2.pageRank.resetProbability(0.15).tol(0.0001)\n",
    "                .run()\n",
    "                .vertices\n",
    "                .orderBy(desc(\"pagerank\"))\n",
    "                .limit(5)\n",
    "                .show\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">STEP 8: Calculate the clustering coefficient of every station</span><br><br>\n",
    "\n",
    "<li>Find the number of triangles that each vertex belongs to in the undirected graph</li>\n",
    "<li>Get the number of adjacent vertices (degrees of the undirected graph)</li>\n",
    "<li>Calculate the number of possible triangles a vertex can belong to (for every vertex)</li>\n",
    "<li>Divide actual triangles by possible triangles for each vertex\n",
    "\n",
    "<li>And report the top 20 stations by clustering coefficient</li>\n",
    "<pre>\n",
    "+----+--------------------+------------------+\n",
    "|  id|            location|             coeff|\n",
    "+----+--------------------+------------------+\n",
    "|3040|     \"GOW Tech Shop\"|               1.0|\n",
    "|3639|        \"Harborside\"|               1.0|\n",
    "|3192|\"Liberty Light Rail\"|               1.0|\n",
    "|3485| \"NYCBS Depot - RIS\"|               1.0|\n",
    "|3647|    \"48 Ave & 30 Pl\"|               1.0|\n",
    "|3279|       \"Dixon Mills\"|               1.0|\n",
    "|3186|     \"Grove St PATH\"|               1.0|\n",
    "| 153|   \"E 40 St & 5 Ave\"|               1.0|\n",
    "| 339|\"Avenue D & E 12 St\"| 0.877201420748853|\n",
    "|3464|\"W 37 St & Broadway\"|0.8679573382796197|\n",
    "| 247|\"Perry St & Bleec...|0.8602079768329604|\n",
    "|3175|\"W 70 St & Amster...|0.8592469808193227|\n",
    "|3176|\"W 64 St & West E...|0.8568452539928423|\n",
    "|3623|\"W 120 St & Clare...|0.8549019607843137|\n",
    "|3491|  \"E 118 St & 1 Ave\"| 0.854122621564482|\n",
    "| 266| \"Avenue D & E 8 St\"| 0.849218980253463|\n",
    "|3441|   \"10 Hudson Yards\"|0.8482701509017299|\n",
    "|3646|    \"35 Ave & 10 St\"|0.8333333333333334|\n",
    "|3642|\"E 98 St & Lexing...|             0.832|\n",
    "| 444|\"Broadway & W 24 St\"|0.8283229697508064|\n",
    "+----+--------------------+------------------+\n",
    "only showing top 20 rows\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val triangles = g.triangleCount.run().withColumnRenamed(\"id\",\"t_id\") //Get the number of triangles each vertex belongs to\n",
    "val degrees = make_undirected_graph(g).degrees //Get the number of adjacent vertices for each vertex\n",
    "val possible = degrees.withColumn(\"possible\",col(\"degree\")*(col(\"degree\")-1)/lit(2)) //Calculate possible triangles\n",
    "val joined = triangles.select(\"t_id\",\"count\").join(possible,triangles(\"t_id\")===possible(\"id\")) \n",
    "val coeff = joined.withColumn(\"coeff\",col(\"count\")/col(\"possible\")).select(\"t_id\",\"coeff\")\n",
    "coeff.join(g.vertices,coeff(\"t_id\")===g.vertices(\"id\"))\n",
    "    .orderBy(desc(\"coeff\"))\n",
    "    .select(\"id\",\"location\",\"coeff\")\n",
    "    .show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
