{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Spark basics practice</h1>\n",
    "<li>The code in the next cell extracts covid data from New York State's covid repository</li>\n",
    "<li>The extracted data is stored in an RDD containing an Array of (String, String,Int,Int) matching (date, borough, positive cases, tests)  (the data is ordered by time</li>\n",
    "<li>Use this RDD to answer the questions below</li>\n",
    "<li>Note: The API for health.data.ny.gov returns 1000 lines for each request. My data starts on 2020-12-04 and ends on 2023-08-30. Your's may be slightly different depending on when you pull the data</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.7.189:4042\n",
       "SparkContext available as 'sc' (version = 3.4.1, master = local[*], app id = local-1698077633628)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "counties: Array[String] = Array(Kings, Queens, New+York, Suffolk, Bronx, Nassau, Westchester, Erie, Monroe, Richmond, Onondaga, Orange, Rockland, Albany, Dutchess, Saratoga, Oneida, Niagara, Broome, Ulster, Rensselaer, Schenectady, Chautauqua, Oswego, Jefferson, Ontario, St.+Lawrence, Tompkins, Putnam, Steuben, Wayne, Chemung, Sullivan, Clinton, Cattaraugus, Cayuga, Madison, Warren, Columbia, Livingston, Washington, Herkimer, Otsego, Genesee, Fulton, Montgomery, Greene, Tioga, Franklin, Chenango, Cortland, Allegany, Delaware, Wyoming, Orleans, Essex, Seneca, Schoharie, Lewis, Yates, Schuyler, Hamilton)\n",
       "base_url: String = https://health.data.ny.gov/resource/xdss-u53e.json?County=\n",
       "urls: Array[String] = Array(https://health.data.ny.gov/resource/xdss-u53e.json?County=Kings, https://health.d...\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//DON'T CHANGE THIS CODE!!!!\n",
    "\n",
    "val counties = Array(\"Kings\",\"Queens\",\"New+York\",\"Suffolk\",\"Bronx\",\"Nassau\",\"Westchester\",\"Erie\",\n",
    "                     \"Monroe\",\"Richmond\",\"Onondaga\",\"Orange\",\"Rockland\",\"Albany\",\"Dutchess\",\n",
    "                     \"Saratoga\",\"Oneida\",\"Niagara\",\"Broome\",\"Ulster\",\"Rensselaer\",\"Schenectady\",\n",
    "                     \"Chautauqua\",\"Oswego\",\"Jefferson\",\"Ontario\",\"St.+Lawrence\",\"Tompkins\",\n",
    "                     \"Putnam\",\"Steuben\",\"Wayne\",\"Chemung\",\"Sullivan\",\"Clinton\",\"Cattaraugus\",\n",
    "                     \"Cayuga\",\"Madison\",\"Warren\",\"Columbia\",\"Livingston\",\"Washington\",\"Herkimer\",\n",
    "                     \"Otsego\",\"Genesee\",\"Fulton\",\"Montgomery\",\"Greene\",\"Tioga\",\"Franklin\",\"Chenango\",\n",
    "                     \"Cortland\",\"Allegany\",\"Delaware\",\"Wyoming\",\"Orleans\"\n",
    "                     ,\"Essex\",\"Seneca\",\"Schoharie\",\"Lewis\",\"Yates\",\"Schuyler\",\"Hamilton\")\n",
    "\n",
    "val base_url = \"https://health.data.ny.gov/resource/xdss-u53e.json?County=\"\n",
    "val urls = counties.map(a => base_url+a) //Makes a url for each county\n",
    "\n",
    "//This gets the contents of the url\n",
    "//results is an array with one entry per county\n",
    "//the data for each county is in JSON format\n",
    "val results = urls.map(u => scala.io.Source.fromURL(u).mkString) \n",
    "\n",
    "//Create an rdd (there is a lot of data)\n",
    "//Reads the json and converts it into a spark dataframe (we'll do this later)\n",
    "//and then converts the df into an rdd\n",
    "//finally, extract the date, the county name, the new cases on that date and tests done\n",
    "//on that date\n",
    "val data_rdd = spark.read.json(sc.parallelize(results,32))\n",
    "                    .rdd\n",
    "                    .map(r => (r(5).toString.slice(0,10), \n",
    "                               r(0).toString,\n",
    "                               r(4).toString.toInt,\n",
    "                               r(7).toString.toInt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_start_date: String = 2020-12-04\n",
       "data_end_date: String = 2023-08-30\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_start_date = data_rdd.filter(t=>t._2==\"Kings\").map(_._1).collect.min\n",
    "val data_end_date = data_rdd.filter(t=>t._2==\"Kings\").map(_._1).collect.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 1</h1>\n",
    "<li>Using <span style=\"color:blue\">reduce</span> calculate the total number of cases and total number of tests in New York State</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_cases_tests: (Int, Int) = (6061104,111330258)\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val total_cases_tests = data_rdd.map(r=> (r._3,r._4))\n",
    "                                .reduce((a,b) => (a._1+b._1,a._2+b._2))\n",
    "// (6061104,111330258)\n",
    "//Your's may be higher or lower but probably not very different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 2</h1>\n",
    "Using <span style=\"color:blue\">reduceByKey</span> calculate the number of cases and total number of tests by county\n",
    "\n",
    "\n",
    "<pre>\n",
    "cases_tests_by_county: Array[(String, (Int, Int))] = Array((Oneida,(64776,1294299)), (Tompkins,(26160,2353515)), (Chemung,(23954,419142)), (Schenectady,(41902,723594)), (Cattaraugus,(18425,256914)), (Greene,(10547,155326)), (Wyoming,(9503,132128)), (Columbia,(13210,205032)), (Chenango,(11492,205982)), (Ulster,(40786,753237)), (Clinton,(22917,369415)), (Wayne,(21395,337507)), (Herkimer,(16998,282726)), (Nassau,(497090,7525925)), (Seneca,(7596,124835)), (Lewis,(7070,92362)), (Broome,(54740,1015959)), (Erie,(247285,3575806)), (Livingston,(13948,242701)), (Bronx,(454349,8224338)), (Allegany,(9928,216499)), (Queens,(785941,13639767)), (Jefferson,(27446,383771)), (Orleans,(10148,140539)), (Putnam,(29271,440648)), (Rensselaer,(40735,757294)), (Ontario,(25574,420044)), (Suffolk,(514280,7630714)...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cases_tests_by_county: Array[(String, (Int, Int))] = Array((Oneida,(64776,1294299)), (Tompkins,(26160,2353515)), (Chemung,(23954,419142)), (Schenectady,(41902,723594)), (Cattaraugus,(18425,256914)), (Greene,(10547,155326)), (Wyoming,(9503,132128)), (Columbia,(13210,205032)), (Chenango,(11492,205982)), (Ulster,(40786,753237)), (Clinton,(22917,369415)), (Wayne,(21395,337507)), (Herkimer,(16998,282726)), (Nassau,(497090,7525925)), (Seneca,(7596,124835)), (Lewis,(7070,92362)), (Broome,(54740,1015959)), (Erie,(247285,3575806)), (Livingston,(13948,242701)), (Bronx,(454349,8224338)), (Allegany,(9928,216499)), (Queens,(785941,13639767)), (Jefferson,(27446,383771)), (Orleans,(10148,140539)), (Putnam,(29271,440648)), (Rensselaer,(40735,757294)), (Ontario,(25574,420044)), (Suffolk,(514280,7630714)...\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cases_tests_by_county =data_rdd.map(r => (r._2,(r._3,r._4))).reduceByKey((a,b) => (a._1 + b._1, a._2 + b._2)).collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 3</h1>\n",
    "Using <span style=\"color:blue\">reduceByKey</span> calculate the positivity by month for New York State. Then use <span style=\"color:blue\">Math.round</span>, <span style=\"color:blue\">sortBy</span>, and <span style=\"color:blue\">collect</span> to display your results as a percentage with 2 decimal places. A sample of the expected result:\n",
    "<pre>\n",
    "(2020-12,5.73)\n",
    "(2021-01,6.27)\n",
    "(2021-02,3.66)\n",
    "(2021-03,3.35)\n",
    "(2021-04,2.69)\n",
    "(2021-05,1.09)\n",
    "(2021-06,0.42)\n",
    "(2021-07,1.56)\n",
    "(2021-08,3.15)\n",
    "(2021-09,2.9)\n",
    "(2021-10,2.31)\n",
    "(2021-11,3.55)\n",
    "(2021-12,10.54)\n",
    "(2022-01,15.09)\n",
    "(2022-02,2.93)\n",
    "(2022-03,1.95)\n",
    "(2022-04,5.45)\n",
    "(2022-05,7.87)\n",
    "(2022-06,5.88)\n",
    "(2022-07,9.54)\n",
    "(2022-08,7.08)\n",
    "(2022-09,6.94)\n",
    "(2022-10,6.82)\n",
    "(2022-11,6.93)\n",
    "(2022-12,8.07)\n",
    "(2023-01,7.49)\n",
    "(2023-02,4.63)\n",
    "(2023-03,2.62)\n",
    "(2023-04,1.92)\n",
    "(2023-05,2.67)\n",
    "(2023-06,4.89)\n",
    "(2023-07,8.82)\n",
    "(2023-08,14.12)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cases_tests_by_month: org.apache.spark.rdd.RDD[(String, (Int, Int))] = ShuffledRDD[22] at reduceByKey at <console>:24\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cases_tests_by_month = data_rdd.map(r => (r._1.slice(0,7),(r._3,r._4))).reduceByKey((a,b) => (a._1 + b._1, a._2 + b._2))//.sortBy(_._2._1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2020-12,5.73)\n",
      "(2021-01,6.27)\n",
      "(2021-02,3.66)\n",
      "(2021-03,3.35)\n",
      "(2021-04,2.69)\n",
      "(2021-05,1.09)\n",
      "(2021-06,0.42)\n",
      "(2021-07,1.56)\n",
      "(2021-08,3.15)\n",
      "(2021-09,2.9)\n",
      "(2021-10,2.31)\n",
      "(2021-11,3.55)\n",
      "(2021-12,10.54)\n",
      "(2022-01,15.09)\n",
      "(2022-02,2.93)\n",
      "(2022-03,1.95)\n",
      "(2022-04,5.45)\n",
      "(2022-05,7.87)\n",
      "(2022-06,5.88)\n",
      "(2022-07,9.54)\n",
      "(2022-08,7.08)\n",
      "(2022-09,6.94)\n",
      "(2022-10,6.82)\n",
      "(2022-11,6.93)\n",
      "(2022-12,8.07)\n",
      "(2023-01,7.49)\n",
      "(2023-02,4.63)\n",
      "(2023-03,2.62)\n",
      "(2023-04,1.92)\n",
      "(2023-05,2.67)\n",
      "(2023-06,4.89)\n",
      "(2023-07,8.82)\n",
      "(2023-08,14.12)\n"
     ]
    }
   ],
   "source": [
    "cases_tests_by_month\n",
    "    .map(t => (t._1,Math.round(t._2._1.toDouble/t._2._2*10000)/100.0))\n",
    "    .sortBy(t=>t._1).collect.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 4</h1>\n",
    "Return an RDD of (date,county,positivity) where positivity is the percentage of tests that are positive. For this problem, you must use the Option case class to handle the case where the divisor is zero\n",
    "\n",
    "<pre>\n",
    "res0: Array[(String, String, Double)] = Array((2023-08-30,Kings,13.0), (2023-08-29,Kings,11.0), (2023-08-28,Kings,12.0), (2023-08-27,Kings,13.0), (2023-08-26,Kings,10.0), (2023-08-25,Kings,11.0), (2023-08-24,Kings,13.0), (2023-08-23,Kings,12.0), (2023-08-22,Kings,11.0), (2023-08-21,Kings,13.0), (2023-08-20,Kings,12.0), (2023-08-19,Kings,11.0), (2023-08-18,Kings,11.0), (2023-08-17,Kings,11.0), (2023-08-16,Kings,11.0), (2023-08-15,Kings,10.0), (2023-08-14,Kings,11.0), (2023-08-13,Kings,12.0), (2023-08-12,Kings,10.0), (2023-08-11,Kings,9.0), (2023-08-10,Kings,12.0), (2023-08-09,Kings,12.0), (2023-08-08,Kings...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "divide: (t: (String, String, Int, Int))Option[(String, String, Double)]\n",
       "positivity: org.apache.spark.rdd.RDD[(String, String, Double)] = MapPartitionsRDD[39] at flatMap at <console>:33\n",
       "res5: Array[(String, String, Double)] = Array((2023-08-30,Kings,13.480885311871228), (2023-08-29,Kings,11.209239130434783), (2023-08-28,Kings,12.693798449612403), (2023-08-27,Kings,13.846153846153847), (2023-08-26,Kings,10.393700787401574), (2023-08-25,Kings,11.889596602972398), (2023-08-24,Kings,13.73825018076645), (2023-08-23,Kings,12.794853466761973), (2023-08-22,Kings,11.842105263157896), (2023-08-21,Kings,13.132400430570506), (2023-08-20,Kings,12.35370611183355), (2023-08-19,Kings,11.458333333333334), (2023-08-18,Kings,11.594202898550725), (2023-08-17,Kings,11.892296185489903), (2023-08-16,Kings,11.6...\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def divide(t: (String,String,Int,Int)): Option[(String,String,Double)] = {\n",
    "    try {\n",
    "        Some((t._1,t._2,100.0*t._3/t._4))\n",
    "    } catch {\n",
    "        case e: Exception => None\n",
    "    }\n",
    "}\n",
    "val positivity = data_rdd.map(t => divide(t)).flatMap(e=>e)\n",
    "positivity.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 5</h1>\n",
    "Return the tuple (date,county,positivity) where the positivity was the highest (use <span style=\"color:blue\">takeOrdered</span>)\n",
    "\n",
    "<pre>\n",
    "Array((2023-07-04,Broome,100.0))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highest_positive: Array[(String, String, Double)] = Array((2023-07-04,Broome,100.0))\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val highest_positive = positivity.takeOrdered(1)(Ordering[Double].on(x => -1*x._3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Array[(String, String, Int, Int)] = Array((2023-07-04,Broome,2,2))\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rdd.filter(t=>t._2 == \"Broome\").filter(t=>t._3==t._4).collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
